[
  {
    "name": "https://arxiv.org/pdf/2010.08422.pdf",
    "url": "https://arxiv.org/pdf/2010.08422.pdf"
  },
  {
    "name": "https://arxiv.org/pdf/2010.08422.pdf",
    "url": "https://arxiv.org/pdf/2010.08422.pdf"
  },
  {
    "name": "https://github.com/wissam-sib/dilbert",
    "url": "https://github.com/wissam-sib/dilbert"
  },
  {
    "name": "https://unifiedqa.apps.allenai.org/",
    "url": "https://unifiedqa.apps.allenai.org/"
  },
  {
    "name": "https://unifiedqa.apps.allenai.org/",
    "url": "https://unifiedqa.apps.allenai.org/"
  },
  {
    "name": "https://arxiv.org/pdf/2005.00038.pdf",
    "url": "https://arxiv.org/pdf/2005.00038.pdf"
  },
  {
    "name": "https://arxiv.org/pdf/2005.00038.pdf",
    "url": "https://arxiv.org/pdf/2005.00038.pdf"
  },
  {
    "name": "https://github.com/xwhan/ProQA",
    "url": "https://github.com/xwhan/ProQA"
  },
  {
    "name": "https://arxiv.org/ftp/arxiv/papers/2003/2003.05002.pdf",
    "url": "https://arxiv.org/ftp/arxiv/papers/2003/2003.05002.pdf"
  },
  {
    "name": "https://arxiv.org/ftp/arxiv/papers/2003/2003.05002.pdf",
    "url": "https://arxiv.org/ftp/arxiv/papers/2003/2003.05002.pdf"
  },
  {
    "name": "https://arxiv.org/pdf/2001.09694v2.pdf",
    "url": "https://arxiv.org/pdf/2001.09694v2.pdf"
  },
  {
    "name": "https://arxiv.org/pdf/2001.09694v2.pdf",
    "url": "https://arxiv.org/pdf/2001.09694v2.pdf"
  },
  {
    "name": "https://arxiv.org/pdf/1911.04118.pdf",
    "url": "https://arxiv.org/pdf/1911.04118.pdf"
  },
  {
    "name": "https://arxiv.org/pdf/1911.04118.pdf",
    "url": "https://arxiv.org/pdf/1911.04118.pdf"
  },
  {
    "name": "ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators",
    "url": "https://openreview.net/pdf?id=r1xMH1BtvB"
  },
  {
    "name": "TinyBERT: Distilling BERT for Natural Language Understanding",
    "url": "https://openreview.net/pdf?id=rJx0Q6EFPB"
  },
  {
    "name": "MINILM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers",
    "url": "https://arxiv.org/abs/2002.10957"
  },
  {
    "name": "T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
    "url": "https://arxiv.org/abs/1910.10683"
  },
  {
    "name": "ERNIE: Enhanced Language Representation with Informative Entities",
    "url": "https://arxiv.org/abs/1905.07129"
  },
  {
    "name": "XLNet: Generalized Autoregressive Pretraining for Language Understanding",
    "url": "https://arxiv.org/abs/1906.08237"
  },
  {
    "name": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations",
    "url": "https://arxiv.org/abs/1909.11942"
  },
  {
    "name": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
    "url": "https://arxiv.org/abs/1907.11692"
  },
  {
    "name": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter",
    "url": "https://arxiv.org/pdf/1910.01108.pdf"
  },
  {
    "name": "SpanBERT: Improving Pre-training by Representing and Predicting Spans",
    "url": "https://arxiv.org/pdf/1907.10529v3.pdf"
  },
  {
    "name": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    "url": "https://arxiv.org/abs/1810.04805"
  },
  {
    "name": "TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection",
    "url": "https://arxiv.org/pdf/1911.04118.pdf"
  },
  {
    "name": "Overview of the MEDIQA 2019 Shared Task on Textual Inference,\nQuestion Entailment and Question Answering",
    "url": "https://www.aclweb.org/anthology/W19-5039"
  },
  {
    "name": "Towards Scalable and Reliable Capsule Networks for Challenging NLP Applications",
    "url": "https://arxiv.org/pdf/1906.02829v1.pdf"
  },
  {
    "name": "Cognitive Graph for Multi-Hop Reading Comprehension at Scale",
    "url": "https://arxiv.org/pdf/1905.05460v2.pdf"
  },
  {
    "name": "Real-Time Open-Domain Question Answering with Dense-Sparse Phrase Index",
    "url": "https://arxiv.org/abs/1906.05807"
  },
  {
    "name": "Unsupervised Question Answering by Cloze Translation",
    "url": "https://arxiv.org/abs/1906.04980"
  },
  {
    "name": "SemEval-2019 Task 10: Math Question Answering",
    "url": "https://www.aclweb.org/anthology/S19-2153"
  },
  {
    "name": "Improving Question Answering over Incomplete KBs with Knowledge-Aware Reader",
    "url": "https://arxiv.org/abs/1905.07098"
  },
  {
    "name": "Matching Article Pairs with Graphical Decomposition and Convolutions",
    "url": "https://arxiv.org/pdf/1802.07459v2.pdf"
  },
  {
    "name": "Episodic Memory Reader: Learning what to Remember for Question Answering from Streaming Data",
    "url": "https://arxiv.org/abs/1903.06164"
  },
  {
    "name": "Natural Questions: a Benchmark for Question Answering Research",
    "url": "https://ai.google/research/pubs/pub47761"
  },
  {
    "name": "Textbook Question Answering with Multi-modal Context Graph Understanding and Self-supervised Open-set Comprehension",
    "url": "https://arxiv.org/abs/1811.00232"
  },
  {
    "name": "Language Models as Knowledge Bases?",
    "url": "https://arxiv.org/pdf/1909.01066v2.pdf"
  },
  {
    "name": "LXMERT: Learning Cross-Modality Encoder Representations from Transformers",
    "url": "https://arxiv.org/pdf/1908.07490v3.pdf"
  },
  {
    "name": "Answering Complex Open-domain Questions Through Iterative Query Generation",
    "url": "https://arxiv.org/pdf/1910.07000v1.pdf"
  },
  {
    "name": "KagNet: Knowledge-Aware Graph Networks for Commonsense Reasoning",
    "url": "https://arxiv.org/pdf/1909.02151v1.pdf"
  },
  {
    "name": "Mixture Content Selection for Diverse Sequence Generation",
    "url": "https://arxiv.org/pdf/1909.01953v1.pdf"
  },
  {
    "name": "A Discrete Hard EM Approach for Weakly Supervised Question Answering",
    "url": "https://arxiv.org/pdf/1909.04849v1.pdf"
  },
  {
    "name": "Investigating the Successes and Failures of BERT for Passage Re-Ranking",
    "url": "https://arxiv.org/abs/1905.01758"
  },
  {
    "name": "BERT with History Answer Embedding for Conversational Question Answering",
    "url": "https://arxiv.org/abs/1905.05412"
  },
  {
    "name": "Understanding the Behaviors of BERT in Ranking",
    "url": "https://arxiv.org/abs/1904.07531"
  },
  {
    "name": "BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis",
    "url": "https://arxiv.org/abs/1904.02232"
  },
  {
    "name": "End-to-End Open-Domain Question Answering with BERTserini",
    "url": "https://arxiv.org/abs/1902.01718"
  },
  {
    "name": "A BERT Baseline for the Natural Questions",
    "url": "https://arxiv.org/abs/1901.08634"
  },
  {
    "name": "Passage Re-ranking with BERT",
    "url": "https://arxiv.org/abs/1901.04085"
  },
  {
    "name": "SDNet: Contextualized Attention-based Deep Network for Conversational Question Answering",
    "url": "https://arxiv.org/abs/1812.03593"
  },
  {
    "name": "ELI5: Long Form Question Answering",
    "url": "https://arxiv.org/abs/1907.09190"
  },
  {
    "name": "CODAH: An Adversarially-Authored Question Answering Dataset for\nCommon Sense",
    "url": "https://www.aclweb.org/anthology/W19-2008.pdf"
  },
  {
    "name": "Morphological analysis",
    "url": "https://www.cs.bham.ac.uk/~pjh/sem1a5/pt2/pt2_intro_morphology.html"
  },
  {
    "name": "Jeopardy!",
    "url": "https://www.jeopardy.com"
  },
  {
    "name": "IBM Watson",
    "url": "https://www.ibm.com/watson/",
    "description": "Has state-of-the-arts performance."
  },
  {
    "name": "Facebook DrQA",
    "url": "https://research.fb.com/downloads/drqa/",
    "description": "Applied to the SQuAD1.0 dataset. The SQuAD2.0 dataset has released. but DrQA is not tested yet."
  },
  {
    "name": "MIT media lab's Knowledge graph",
    "url": "http://conceptnet.io/",
    "description": "Is a freely-available semantic network, designed to help computers understand the meanings of words that people use."
  },
  {
    "name": "\"Learning to Skim Text\"",
    "url": "https://arxiv.org/pdf/1704.06877.pdf"
  },
  {
    "name": "\"Learning to Skim Text\"",
    "url": "https://arxiv.org/pdf/1704.06877.pdf"
  },
  {
    "name": "\"Deep Joint Entity Disambiguation with Local Neural Attention\"",
    "url": "https://arxiv.org/pdf/1704.04920.pdf"
  },
  {
    "name": "\"BI-DIRECTIONAL ATTENTION FLOW FOR MACHINE COMPREHENSION\"",
    "url": "https://arxiv.org/pdf/1611.01603.pdf"
  },
  {
    "name": "\"Capturing Semantic Similarity for Entity Linking with Convolutional Neural Networks\"",
    "url": "http://nlp.cs.berkeley.edu/pubs/FrancisLandau-Durrett-Klein_2016_EntityConvnets_paper.pdf"
  },
  {
    "name": "https://GitHub.com/matthewfl/nlp-entity-convnet",
    "url": "https://GitHub.com/matthewfl/nlp-entity-convnet"
  },
  {
    "name": "\"Entity Linking with a Knowledge Base: Issues, Techniques, and Solutions\"",
    "url": "https://ieeexplore.ieee.org/document/6823700/"
  },
  {
    "name": "\"Introduction to â€œThis is Watson\"",
    "url": "https://ieeexplore.ieee.org/document/6177724/"
  },
  {
    "name": "\"A survey on question answering technology from an information retrieval perspective\"",
    "url": "https://www.sciencedirect.com/science/article/pii/S0020025511003860"
  },
  {
    "name": "\"Question Answering in Restricted Domains: An Overview\"",
    "url": "https://www.mitpressjournals.org/doi/abs/10.1162/coli.2007.33.1.41"
  },
  {
    "name": "BiDAF",
    "url": "https://github.com/allenai/bi-att-flow",
    "description": "Bi-Directional Attention Flow (BIDAF) network is a multi-stage hierarchical process that represents the context at different levels of granularity and uses bi-directional attention flow mechanism to obtain a query-aware context representation without early summarization."
  },
  {
    "name": "Paper",
    "url": "https://arxiv.org/pdf/1611.01603.pdf"
  },
  {
    "name": "QANet",
    "url": "https://github.com/NLPLearn/QANet",
    "description": "A Q&A architecture does not require recurrent networks: Its encoder consists exclusively of convolution and self-attention, where convolution models local interactions and self-attention models global interactions."
  },
  {
    "name": "R-Net",
    "url": "https://github.com/HKUST-KnowComp/R-Net",
    "description": "An end-to-end neural networks model for reading comprehension style question answering, which aims to answer questions from a given passage."
  },
  {
    "name": "Paper",
    "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf"
  },
  {
    "name": "R-Net-in-Keras",
    "url": "https://github.com/YerevaNN/R-NET-in-Keras",
    "description": "R-NET re-implementation in Keras."
  },
  {
    "name": "Paper",
    "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf"
  },
  {
    "name": "DrQA",
    "url": "https://github.com/hitvoice/DrQA",
    "description": "DrQA is a system for reading comprehension applied to open-domain question answering."
  },
  {
    "name": "BERT",
    "url": "https://github.com/google-research/bert",
    "description": "A new language representation model which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers."
  },
  {
    "name": "Paper",
    "url": "https://arxiv.org/abs/1810.04805"
  },
  {
    "name": "Question Answering - Natural Language Processing",
    "url": "https://youtu.be/Kzi6tE4JaGo",
    "description": "Natural Language Processing - By Dragomir Radev, Ph.D. | University of Michigan | 2016."
  },
  {
    "name": "Question Answering with Knowledge Bases, Web and Beyond",
    "url": "https://github.com/scottyih/Slides/blob/master/QA%20Tutorial.pdf",
    "description": "By Scott Wen-tau Yih & Hao Ma | Microsoft Research | 2016."
  },
  {
    "name": "Question Answering",
    "url": "https://hpi.de/fileadmin/user_upload/fachgebiete/plattner/teaching/NaturalLanguageProcessing/NLP2017/NLP8_QuestionAnswering.pdf",
    "description": "By Dr. Mariana Neves | Hasso Plattner Institut | 2017."
  },
  {
    "name": "NLIWOD's Question answering datasets",
    "url": "https://github.com/dice-group/NLIWOD/tree/master/qa.datasets"
  },
  {
    "name": "karthinkncode's Datasets for Natural Language Processing",
    "url": "https://github.com/karthikncode/nlp-datasets"
  },
  {
    "name": "AI2 Science Questions v2.1(2017)",
    "url": "http://data.allenai.org/ai2-science-questions/"
  },
  {
    "name": "http://ai2-website.s3.amazonaws.com/publications/AI2ReasoningChallenge2018.pdf",
    "url": "http://ai2-website.s3.amazonaws.com/publications/AI2ReasoningChallenge2018.pdf"
  },
  {
    "name": "Children's Book Test",
    "url": "https://uclmr.github.io/ai4exams/data.html"
  },
  {
    "name": "CODAH Dataset",
    "url": "https://github.com/Websail-NU/CODAH"
  },
  {
    "name": "DeepMind Q&A Dataset; CNN/Daily Mail",
    "url": "https://github.com/deepmind/rc-data"
  },
  {
    "name": "https://arxiv.org/abs/1506.03340",
    "url": "https://arxiv.org/abs/1506.03340"
  },
  {
    "name": "ELI5",
    "url": "https://github.com/facebookresearch/ELI5"
  },
  {
    "name": "https://arxiv.org/abs/1907.09190",
    "url": "https://arxiv.org/abs/1907.09190"
  },
  {
    "name": "GraphQuestions",
    "url": "https://github.com/ysu1989/GraphQuestions"
  },
  {
    "name": "LC-QuAD",
    "url": "http://sda.cs.uni-bonn.de/projects/qa-dataset/"
  },
  {
    "name": "MS MARCO",
    "url": "http://www.msmarco.org/dataset.aspx"
  },
  {
    "name": "https://arxiv.org/abs/1611.09268",
    "url": "https://arxiv.org/abs/1611.09268"
  },
  {
    "name": "MultiRC",
    "url": "https://cogcomp.org/multirc/"
  },
  {
    "name": "http://cogcomp.org/page/publication_view/833",
    "url": "http://cogcomp.org/page/publication_view/833"
  },
  {
    "name": "NarrativeQA",
    "url": "https://github.com/deepmind/narrativeqa"
  },
  {
    "name": "https://arxiv.org/pdf/1712.07040v1.pdf",
    "url": "https://arxiv.org/pdf/1712.07040v1.pdf"
  },
  {
    "name": "NewsQA",
    "url": "https://github.com/Maluuba/newsqa"
  },
  {
    "name": "https://arxiv.org/pdf/1611.09830.pdf",
    "url": "https://arxiv.org/pdf/1611.09830.pdf"
  },
  {
    "name": "Qestion-Answer Dataset by CMU",
    "url": "http://www.cs.cmu.edu/~ark/QA-data/"
  },
  {
    "name": "SQuAD1.0",
    "url": "https://rajpurkar.github.io/SQuAD-explorer/"
  },
  {
    "name": "https://arxiv.org/abs/1606.05250",
    "url": "https://arxiv.org/abs/1606.05250"
  },
  {
    "name": "SQuAD2.0",
    "url": "https://rajpurkar.github.io/SQuAD-explorer/"
  },
  {
    "name": "https://arxiv.org/abs/1806.03822",
    "url": "https://arxiv.org/abs/1806.03822"
  },
  {
    "name": "Story cloze test",
    "url": "http://cs.rochester.edu/nlp/rocstories/"
  },
  {
    "name": "https://arxiv.org/abs/1604.01696",
    "url": "https://arxiv.org/abs/1604.01696"
  },
  {
    "name": "TriviaQA",
    "url": "http://nlp.cs.washington.edu/triviaqa/"
  },
  {
    "name": "https://arxiv.org/abs/1705.03551",
    "url": "https://arxiv.org/abs/1705.03551"
  },
  {
    "name": "WikiQA",
    "url": "https://www.microsoft.com/en-us/download/details.aspx?id=52419&from=https%3A%2F%2Fresearch.microsoft.com%2Fen-US%2Fdownloads%2F4495da01-db8c-4041-a7f6-7984a4f6a905%2Fdefault.aspx"
  },
  {
    "name": "\"Unsupervised Entity-Relation Analysis in IBM Watson\"",
    "url": "http://www.cogsys.org/papers/ACS2015/article12.pdf"
  },
  {
    "name": "\"Unsupervised Entity-Relation Analysis in IBM Watson\"",
    "url": "http://www.cogsys.org/papers/ACS2015/article12.pdf"
  },
  {
    "name": "\"WatsonPaths: Scenario-based Question Answering and Inference over Unstructured Information\"",
    "url": "http://domino.watson.ibm.com/library/Cyberdig.nsf/1e4115aea78b6e7c85256b360066f0d4/088f74984a07645485257d5f006ace96!OpenDocument&Highlight=0,RC25489"
  },
  {
    "name": "\"WatsonPaths: Scenario-based Question Answering and Inference over Unstructured Information\"",
    "url": "http://domino.watson.ibm.com/library/Cyberdig.nsf/1e4115aea78b6e7c85256b360066f0d4/088f74984a07645485257d5f006ace96!OpenDocument&Highlight=0,RC25489"
  },
  {
    "name": "\"Medical Relation Extraction with Manifold Models\"",
    "url": "http://acl2014.org/acl2014/P14-1/pdf/P14-1078.pdf"
  },
  {
    "name": "\"FigureQA: An Annotated Figure Dataset for Visual Reasoning\"",
    "url": "https://arxiv.org/abs/1710.07300"
  },
  {
    "name": "\"FigureQA: An Annotated Figure Dataset for Visual Reasoning\"",
    "url": "https://arxiv.org/abs/1710.07300"
  },
  {
    "name": "\"Stacked Attention Networks for Image Question Answering\"",
    "url": "https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Yang_Stacked_Attention_Networks_CVPR_2016_paper.html"
  },
  {
    "name": "\"Stacked Attention Networks for Image Question Answering\"",
    "url": "https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Yang_Stacked_Attention_Networks_CVPR_2016_paper.html"
  },
  {
    "name": "\"Question Answering with Knowledge Base, Web and Beyond\"",
    "url": "https://www.microsoft.com/en-us/research/publication/question-answering-with-knowledge-base-web-and-beyond/"
  },
  {
    "name": "\"NewsQA: A Machine Comprehension Dataset\"",
    "url": "https://arxiv.org/abs/1611.09830"
  },
  {
    "name": "\"Table Cell Search for Question Answering\"",
    "url": "https://dl.acm.org/citation.cfm?id=2883080"
  },
  {
    "name": "\"WIKIQA: A Challenge Dataset for Open-Domain Question Answering\"",
    "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/YangYihMeek_EMNLP-15_WikiQA.pdf"
  },
  {
    "name": "\"WIKIQA: A Challenge Dataset for Open-Domain Question Answering\"",
    "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/YangYihMeek_EMNLP-15_WikiQA.pdf"
  },
  {
    "name": "\"Web-based Question Answering: Revisiting AskMSR\"",
    "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/AskMSRPlusTR_082815.pdf"
  },
  {
    "name": "\"Open Domain Question Answering via Semantic Enrichment\"",
    "url": "https://dl.acm.org/citation.cfm?id=2741651"
  },
  {
    "name": "\"An Overview of Microsoft Deep QA System on Stanford WebQuestions Benchmark\"",
    "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/Microsoft20Deep20QA.pdf"
  },
  {
    "name": "\"An Overview of Microsoft Deep QA System on Stanford WebQuestions Benchmark\"",
    "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/Microsoft20Deep20QA.pdf"
  },
  {
    "name": "\"QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension\"",
    "url": "https://openreview.net/pdf?id=B14TlG-RW"
  },
  {
    "name": "\"QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension\"",
    "url": "https://openreview.net/pdf?id=B14TlG-RW"
  },
  {
    "name": "\"QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension\"",
    "url": "https://openreview.net/pdf?id=B14TlG-RW"
  },
  {
    "name": "\"Ask the Right Questions: Active Question Reformulation with Reinforcement Learning\"",
    "url": "https://openreview.net/pdf?id=S1CChZ-CZ"
  },
  {
    "name": "\"Building Large Machine Reading-Comprehension Datasets using Paragraph Vectors\"",
    "url": "https://arxiv.org/pdf/1612.04342.pdf"
  },
  {
    "name": "\"An efficient framework for learning sentence representations\"",
    "url": "https://arxiv.org/pdf/1803.02893.pdf"
  },
  {
    "name": "\"An efficient framework for learning sentence representations\"",
    "url": "https://arxiv.org/pdf/1803.02893.pdf"
  },
  {
    "name": "\"Did the model understand the question?\"",
    "url": "https://arxiv.org/pdf/1805.05492.pdf"
  },
  {
    "name": "\"Analyzing Language Learned by an Active Question Answering Agent\"",
    "url": "https://arxiv.org/pdf/1801.07537.pdf"
  },
  {
    "name": "\"Analyzing Language Learned by an Active Question Answering Agent\"",
    "url": "https://arxiv.org/pdf/1801.07537.pdf"
  },
  {
    "name": "\"Learning Recurrent Span Representations for Extractive Question Answering\"",
    "url": "https://arxiv.org/pdf/1611.01436.pdf"
  },
  {
    "name": "\"Neural Paraphrase Identification of Questions with Noisy Pretraining\"",
    "url": "https://arxiv.org/pdf/1704.04565.pdf"
  },
  {
    "name": "\"Neural Paraphrase Identification of Questions with Noisy Pretraining\"",
    "url": "https://arxiv.org/pdf/1704.04565.pdf"
  },
  {
    "name": "Embodied Question Answering",
    "url": "https://research.fb.com/publications/embodied-question-answering/"
  },
  {
    "name": "Embodied Question Answering",
    "url": "https://research.fb.com/publications/embodied-question-answering/"
  },
  {
    "name": "Do explanations make VQA models more predictable to a human?",
    "url": "https://research.fb.com/publications/do-explanations-make-vqa-models-more-predictable-to-a-human/"
  },
  {
    "name": "Neural Compositional Denotational Semantics for Question Answering",
    "url": "https://research.fb.com/publications/neural-compositional-denotational-semantics-for-question-answering/"
  },
  {
    "name": "Reading Wikipedia to Answer Open-Domain Questions",
    "url": "https://cs.stanford.edu/people/danqi/papers/acl2017.pdf"
  },
  {
    "name": "Reading Wikipedia to Answer Open-Domain Questions",
    "url": "https://cs.stanford.edu/people/danqi/papers/acl2017.pdf"
  },
  {
    "name": "Reading Wikipedia to Answer Open-Domain Questions",
    "url": "https://cs.stanford.edu/people/danqi/papers/acl2017.pdf"
  },
  {
    "name": "Building a Question-Answering System from Scratchâ€” Part 1",
    "url": "https://towardsdatascience.com/building-a-question-answering-system-part-1-9388aadff507"
  },
  {
    "name": "Qeustion Answering with Tensorflow By Steven Hewitt, O'REILLY, 2017",
    "url": "https://www.oreilly.com/ideas/question-answering-with-tensorflow"
  },
  {
    "name": "Why question answering is hard",
    "url": "http://nicklothian.com/blog/2014/09/25/why-question-answering-is-hard/"
  }
]